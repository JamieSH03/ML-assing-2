{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0aab0d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, cohen_kappa_score, matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9184b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"../forestCover.csv\", na_values=\"?\")\n",
    "raw_df = raw_df.rename(columns={\"Observation_ID\":\"Water_Level\" , \"Water_Level\":\"Observation_ID\"})\n",
    "# display(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7669363b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(298)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_col = raw_df.columns[raw_df.isna().any()]\n",
    "# print(na_col)\n",
    "raw_df[\"Slope\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a210d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr of Inclination and Cover: 0.0002417782055169697\n",
      "Corr of aspect and facet: 0.9999980536139016\n",
      "Cardinality of water level: 1\n",
      "Cardinality of obs id: 581012\n",
      "Cover_Type\n",
      "1    0.045\n",
      "2    0.055\n",
      "3    0.053\n",
      "4    0.036\n",
      "5    0.021\n",
      "6    0.069\n",
      "7    0.054\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Soil_Type1\n",
       "1    577685\n",
       "0      3029\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Corr of Inclination and Cover: {raw_df['Inclination'].corr(raw_df['Cover_Type'])}\")\n",
    "print(f\"Corr of aspect and facet: {raw_df['Facet'].corr(raw_df['Aspect'])}\")\n",
    "print(f\"Cardinality of water level: {raw_df['Water_Level'].nunique()}\")\n",
    "print(f\"Cardinality of obs id: {raw_df['Observation_ID'].nunique()}\")\n",
    "df = raw_df.drop(columns={'Facet','Water_Level','Observation_ID', 'Inclination' })\n",
    "\n",
    "na_rows = df.index[df.isna().any(axis=1)]\n",
    "na_proportions = (df[\"Cover_Type\"][na_rows].value_counts() /  df[\"Cover_Type\"].value_counts() * 100).round(3)\n",
    "print(na_proportions)\n",
    "df = df.dropna()\n",
    "\n",
    "df[\"Soil_Type1\"] = (df[\"Soil_Type1\"] == 'positive').astype(int)\n",
    "df[\"Soil_Type1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb54ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\"\n",
    "]\n",
    "\n",
    "# # Plot distributions\n",
    "# fig, axes = plt.subplots(len(continuous_features), 1, figsize=(5, 15))\n",
    "\n",
    "# for i, col in enumerate(continuous_features):\n",
    "#     sns.histplot(df[col], bins=50, kde=True, ax=axes[i], color=\"steelblue\")\n",
    "#     axes[i].set_title(f\"Distribution of {col}\")\n",
    "#     axes[i].set_xlabel(\"\")\n",
    "#     axes[i].set_ylabel(\"Count\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5da20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = df.copy()\n",
    "df_eng[\"Relative_hoz_dist_mean\"] = df[[\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Horizontal_Distance_To_Roadways\"\n",
    "]].mean(axis=1)\n",
    "\n",
    "df_eng[\"total_hillshade\"] = df[[\"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\"]].sum(axis=1)\n",
    "df_eng[\"Relative_height_from_water\"] = df[\"Elevation\"] - df[\"Vertical_Distance_To_Hydrology\"]\n",
    "df_eng = df_eng.drop(columns={\"Elevation\",  \"Vertical_Distance_To_Hydrology\",\"Horizontal_Distance_To_Hydrology\", \"Horizontal_Distance_To_Fire_Points\",\"Horizontal_Distance_To_Roadways\",\"Hillshade_9am\",\"Hillshade_Noon\", \"Hillshade_3pm\"  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c505da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns={\"Cover_Type\"})\n",
    "X_eng = df_eng.drop(columns={\"Cover_Type\"})\n",
    "y = df[\"Cover_Type\"]\n",
    "y_eng = df_eng[\"Cover_Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "eX_train, eX_test, ey_train, ey_test = train_test_split(X_eng, y_eng, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78f4bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_features = [\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "]\n",
    "\n",
    "outlier_features_eng = [\n",
    "    \"Relative_hoz_dist_mean\",\n",
    "    \n",
    "]\n",
    "\n",
    "knn_df = df.copy()\n",
    "knn_eng = df_eng.copy()\n",
    "\n",
    "\n",
    "def clamp_series(s, lower_q=0.01, upper_q=0.99):\n",
    "    lower, upper = s.quantile([lower_q, upper_q])\n",
    "    return s.clip(lower, upper)\n",
    "\n",
    "# apply clamping\n",
    "for col in outlier_features:\n",
    "    knn_df[col] = clamp_series(knn_df[col], 0.01, 0.99)\n",
    "    \n",
    "\n",
    "knn_eng[\"Relative_hoz_dist_mean\"] = clamp_series(knn_eng[\"Relative_hoz_dist_mean\"], 0.01, 0.99)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "continuous_features = [\n",
    "\n",
    "    \"Elevation\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "]\n",
    "\n",
    "continuous_features_eng = [\n",
    "\n",
    "    'Slope', \n",
    "    'Relative_hoz_dist_mean', \n",
    "    'total_hillshade',\n",
    "    'Relative_height_from_water'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scale_knn(knn_df, continuous_features = continuous_features):\n",
    "    scaler = MinMaxScaler()\n",
    "    knn_df[continuous_features] = scaler.fit_transform(knn_df[continuous_features])\n",
    "    knn_df[\"Aspect_rad\"] = np.deg2rad(knn_df[\"Aspect\"])\n",
    "    knn_df[\"Aspect_sin\"] = np.sin(knn_df[\"Aspect_rad\"])\n",
    "    knn_df[\"Aspect_cos\"] = np.cos(knn_df[\"Aspect_rad\"])\n",
    "    knn_df.drop(columns=[\"Aspect\", \"Aspect_rad\"] , inplace=True)\n",
    "\n",
    "\n",
    "scale_knn(knn_df)\n",
    "scale_knn(knn_eng, continuous_features_eng)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95985ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns={\"Cover_Type\"})\n",
    "X_eng = df_eng.drop(columns={\"Cover_Type\"})\n",
    "y = df[\"Cover_Type\"]\n",
    "y_eng = df_eng[\"Cover_Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "eX_train, eX_test, ey_train, ey_test = train_test_split(X_eng, y_eng, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e79a8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "kX = df.drop(columns={\"Cover_Type\"})\n",
    "kX_eng = df_eng.drop(columns={\"Cover_Type\"})\n",
    "ky = df[\"Cover_Type\"]\n",
    "ky_eng = df_eng[\"Cover_Type\"]\n",
    "\n",
    "kX_train, kX_test, ky_train, ky_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "keX_train, keX_test, key_train, key_test = train_test_split(X_eng, y_eng, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dfd4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.9)\n",
    "X_pca = pca.fit_transform(X)\n",
    "kX_pca = pca.fit(kX)\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "kX_train_pca, kX_test_pca, ky_train_pca, ky_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc79693",
   "metadata": {},
   "source": [
    "## dealing with class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66c22edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamie\\anaconda3\\envs\\datsci\\Lib\\site-packages\\threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "tomek = TomekLinks(sampling_strategy='auto')\n",
    "X_tomek, y_tomek = tomek.fit_resample(X_train, y_train)\n",
    "eX_tomek, ey_tomek = tomek.fit_resample(eX_train, ey_train)\n",
    "\n",
    "kX_tomek, ky_tomek = tomek.fit_resample(kX_train, ky_train)\n",
    "keX_tomek, key_tomek = tomek.fit_resample(keX_train, key_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf338cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTETomek(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "eX_smote, ey_smote = smote.fit_resample(eX_train, ey_train)\n",
    "pca_X_smote, pca_y_smote = smote.fit_resample(X_train_pca, y_train_pca)\n",
    "\n",
    "\n",
    "kX_smote, ky_smote = smote.fit_resample(kX_train, ky_train)\n",
    "keX_smote, key_smote = smote.fit_resample(keX_train, key_train)\n",
    "pca_kXsmote, pca_kysmote = smote.fit_resample(kX_train_pca, ky_train_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fc1dd",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e2fe64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, cv=5):\n",
    "    # Accuracy with mean ± std\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    print(f\"Accuracy: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "    \n",
    "    # Cross-validated predictions for confusion matrix etc.\n",
    "    y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix ({type(model).__name__})\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification report (precision, recall, f1 per class)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, y_pred, digits=3))\n",
    "    \n",
    "    # Cohen’s kappa (agreement beyond chance)\n",
    "    kappa = cohen_kappa_score(y, y_pred)\n",
    "    print(f\"Cohen’s Kappa: {kappa:.3f}\")\n",
    "\n",
    "def plot_cv_boxplot(model, X, y, cv=5):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    sns.boxplot(data=scores, orient=\"h\", color=\"skyblue\")\n",
    "    plt.title(f\"Accuracy per fold ({type(model).__name__})\")\n",
    "    plt.xlabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, cv=cv, train_sizes=train_sizes, scoring=\"accuracy\"\n",
    "    )\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(train_sizes, train_mean, \"o-\", label=\"Training\")\n",
    "    plt.plot(train_sizes, val_mean, \"o-\", label=\"Validation\")\n",
    "    plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, alpha=0.2)\n",
    "    plt.fill_between(train_sizes, val_mean-val_std, val_mean+val_std, alpha=0.2)\n",
    "    plt.title(f\"Learning Curve ({type(model).__name__})\")\n",
    "    plt.xlabel(\"Training set size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a716a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84f911a2",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d83467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_knn(X_train , y_train, X_test = kX_test, y_test = ky_test, weights = 'distance' , k = 7, metric = \"euclidean\"):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights=weights)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_acc = knn.score(X_train, y_train)\n",
    "    test_acc = knn.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4c66da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.7988\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.7481\n"
     ]
    }
   ],
   "source": [
    "test_knn(kX_tomek, ky_tomek)\n",
    "test_knn(keX_tomek, key_tomek, X_test=keX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afc4de72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         1\n",
       "2         1\n",
       "3         2\n",
       "4         7\n",
       "         ..\n",
       "862031    7\n",
       "862032    7\n",
       "862033    7\n",
       "862034    7\n",
       "862035    7\n",
       "Name: Cover_Type, Length: 862036, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pca_kysmote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a9400d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.7538\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.6812\n"
     ]
    }
   ],
   "source": [
    "test_knn(kX_smote, ky_smote)\n",
    "test_knn(keX_smote, key_smote, X_test=keX_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4ee9b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.3054\n"
     ]
    }
   ],
   "source": [
    "test_knn(pca_kXsmote, pca_kysmote, X_test=X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b1205af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.7538\n"
     ]
    }
   ],
   "source": [
    "test_knn(kX_smote, ky_smote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c1e39",
   "metadata": {},
   "source": [
    "### tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e684adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tree(X_train, y_train, X_test = X_test, y_test = y_test, metric = 'entropy', max_depth = None):\n",
    "    tree = DecisionTreeClassifier(criterion = metric, max_depth= max_depth, random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    train_acc = tree.score(X_train, y_train)\n",
    "    test_acc = tree.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Smote train acc: {train_acc}\")\n",
    "    print(f\"Smote test acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0057f6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smote train acc: 1.0\n",
      "Smote test acc: 0.9339379502339064\n",
      "Smote train acc: 1.0\n",
      "Smote test acc: 0.8703039347932153\n"
     ]
    }
   ],
   "source": [
    "test_tree(X_tomek, y_tomek)\n",
    "test_tree(eX_tomek, ey_tomek, X_test=eX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61d187aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4677.6435595 ],\n",
       "       [-4592.3962554 ],\n",
       "       [-4854.59285615],\n",
       "       ...,\n",
       "       [-4991.34453709],\n",
       "       [-4763.26645612],\n",
       "       [-5025.19968416]], shape=(174215, 1))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c5af5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smote train acc: 1.0\n",
      "Smote test acc: 0.9329277042734552\n",
      "Smote train acc: 1.0\n",
      "Smote test acc: 0.868082541686996\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "test_tree() got an unexpected keyword argument 'k'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m test_tree(X_smote, y_smote)\n\u001b[32m      2\u001b[39m test_tree(eX_smote, ey_smote, X_test=eX_test)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtest_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpca_X_smote\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpca_y_smote\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: test_tree() got an unexpected keyword argument 'k'"
     ]
    }
   ],
   "source": [
    "test_tree(X_smote, y_smote)\n",
    "test_tree(eX_smote, ey_smote, X_test=eX_test)\n",
    "test_tree(pca_X_smote,pca_y_smote, X_test = X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = df.copy()\n",
    "df_eng[\"ExS\"] = df[\"Elevation\"] * df[\"Slope\"]\n",
    "\n",
    "# Row-wise min/max/mean\n",
    "df_eng[\"Relative_hoz_dist_min\"] = df[[\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Horizontal_Distance_To_Roadways\"\n",
    "]].min(axis=1)\n",
    "\n",
    "df_eng[\"Relative_hoz_dist_max\"] = df[[\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Horizontal_Distance_To_Roadways\"\n",
    "]].max(axis=1)\n",
    "\n",
    "df_eng[\"Relative_hoz_dist_mean\"] = df[[\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Horizontal_Distance_To_Roadways\"\n",
    "]].mean(axis=1)\n",
    "\n",
    "df_eng[\"total_hillshade\"] = df[[\"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\"]].sum(axis=1)\n",
    "df_eng[\"min_hillshade\"]   = df[[\"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\"]].min(axis=1)\n",
    "df_eng[\"max_hillshade\"]   = df[[\"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\"]].max(axis=1)\n",
    "\n",
    "df_eng[\"Relative_height_from_water\"] = df[\"Elevation\"] - df[\"Vertical_Distance_To_Hydrology\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fca39368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>q1</th>\n",
       "      <th>median</th>\n",
       "      <th>q3</th>\n",
       "      <th>max</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>CV</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>ANOVA_F</th>\n",
       "      <th>ANOVA_p</th>\n",
       "      <th>MI</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Relative_height_from_water</th>\n",
       "      <td>3270051.550</td>\n",
       "      <td>309380.218</td>\n",
       "      <td>2054184.000</td>\n",
       "      <td>3103927.000</td>\n",
       "      <td>3310510.000</td>\n",
       "      <td>3495121.750</td>\n",
       "      <td>4263008.000</td>\n",
       "      <td>391194.750</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>155254.905</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.576</td>\n",
       "      <td>580714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative_hoz_dist_mean</th>\n",
       "      <td>3131.804</td>\n",
       "      <td>317524.972</td>\n",
       "      <td>34.000</td>\n",
       "      <td>935.000</td>\n",
       "      <td>1398.000</td>\n",
       "      <td>1971.333</td>\n",
       "      <td>124764839.667</td>\n",
       "      <td>1036.333</td>\n",
       "      <td>257.179</td>\n",
       "      <td>101.387</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.268</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.139</td>\n",
       "      <td>580714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_hillshade</th>\n",
       "      <td>577.995</td>\n",
       "      <td>43.396</td>\n",
       "      <td>95.000</td>\n",
       "      <td>557.000</td>\n",
       "      <td>586.000</td>\n",
       "      <td>609.000</td>\n",
       "      <td>641.000</td>\n",
       "      <td>52.000</td>\n",
       "      <td>-1.290</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3241.520</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>580714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean         std          min           q1  \\\n",
       "Relative_height_from_water  3270051.550  309380.218  2054184.000  3103927.000   \n",
       "Relative_hoz_dist_mean         3131.804  317524.972       34.000      935.000   \n",
       "total_hillshade                 577.995      43.396       95.000      557.000   \n",
       "\n",
       "                                 median           q3            max  \\\n",
       "Relative_height_from_water  3310510.000  3495121.750    4263008.000   \n",
       "Relative_hoz_dist_mean         1398.000     1971.333  124764839.667   \n",
       "total_hillshade                 586.000      609.000        641.000   \n",
       "\n",
       "                                   IQR     skew       CV missing_%  \\\n",
       "Relative_height_from_water  391194.750   -0.818    0.095     0.000   \n",
       "Relative_hoz_dist_mean        1036.333  257.179  101.387     0.000   \n",
       "total_hillshade                 52.000   -1.290    0.075     0.000   \n",
       "\n",
       "                               ANOVA_F ANOVA_p     MI   count  \n",
       "Relative_height_from_water  155254.905   0.000  0.576  580714  \n",
       "Relative_hoz_dist_mean           1.268   0.268  0.139  580714  \n",
       "total_hillshade               3241.520   0.000  0.019  580714  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative_hoz_dist_mean</th>\n",
       "      <th>total_hillshade</th>\n",
       "      <th>Relative_height_from_water</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__y__</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3316.903</td>\n",
       "      <td>579.306</td>\n",
       "      <td>3457108.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3282.190</td>\n",
       "      <td>582.155</td>\n",
       "      <td>3227579.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1336.154</td>\n",
       "      <td>558.115</td>\n",
       "      <td>2645819.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16207.301</td>\n",
       "      <td>556.740</td>\n",
       "      <td>2457373.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4893.251</td>\n",
       "      <td>564.441</td>\n",
       "      <td>3080062.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750.775</td>\n",
       "      <td>550.964</td>\n",
       "      <td>2673175.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1721.608</td>\n",
       "      <td>573.649</td>\n",
       "      <td>3714850.237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Relative_hoz_dist_mean total_hillshade Relative_height_from_water\n",
       "__y__                                                                  \n",
       "1                   3316.903         579.306                3457108.651\n",
       "2                   3282.190         582.155                3227579.840\n",
       "3                   1336.154         558.115                2645819.212\n",
       "4                  16207.301         556.740                2457373.771\n",
       "5                   4893.251         564.441                3080062.083\n",
       "6                    750.775         550.964                2673175.076\n",
       "7                   1721.608         573.649                3714850.237"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "\n",
    "# ---- 1) Configure your engineered features here ----\n",
    "eng_cols = [\n",
    "    \"Relative_hoz_dist_mean\",\n",
    "    \"total_hillshade\",\n",
    "    \"Relative_height_from_water\",\n",
    "]\n",
    "\n",
    "# df = your original frame, df_eng = engineered columns frame with the cols above\n",
    "# y should be a 1D array/Series of your class labels (same index as df/df_eng)\n",
    "\n",
    "def summarize_engineered_features(df_eng: pd.DataFrame, y: pd.Series, eng_cols: list):\n",
    "    \"\"\"Return a tidy summary table comparing engineered features:\n",
    "       descriptives + ANOVA F + Mutual Information vs multiclass target y.\n",
    "    \"\"\"\n",
    "    # Keep numeric only (coerce junk to NaN)\n",
    "    X = df_eng[eng_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Descriptive statistics\n",
    "    desc = pd.DataFrame(index=eng_cols)\n",
    "    desc[\"count\"]     = X.notna().sum()\n",
    "    desc[\"missing_%\"] = (1 - X.notna().mean()) * 100\n",
    "    desc[\"mean\"]      = X.mean()\n",
    "    desc[\"std\"]       = X.std(ddof=1)\n",
    "    desc[\"min\"]       = X.min()\n",
    "    desc[\"q1\"]        = X.quantile(0.25)\n",
    "    desc[\"median\"]    = X.quantile(0.50)\n",
    "    desc[\"q3\"]        = X.quantile(0.75)\n",
    "    desc[\"max\"]       = X.max()\n",
    "    desc[\"IQR\"]       = desc[\"q3\"] - desc[\"q1\"]\n",
    "    # robust skew (ignore NaN)\n",
    "    desc[\"skew\"]      = X.apply(lambda s: skew(s.dropna(), bias=False) if s.dropna().size > 2 else np.nan)\n",
    "    # coefficient of variation (avoid div by zero)\n",
    "    desc[\"CV\"]        = desc[\"std\"] / desc[\"mean\"].replace({0: np.nan})\n",
    "\n",
    "    # Predictive signal (align y, drop rows with any NaN in X)\n",
    "    mask = X.notna().all(axis=1) & pd.notna(y)\n",
    "    X_clean = X.loc[mask, :]\n",
    "    y_clean = y.loc[mask]\n",
    "\n",
    "    # ANOVA F (needs finite)\n",
    "    F_vals, p_vals = f_classif(X_clean.values, y_clean.values)\n",
    "    mi_vals = mutual_info_classif(X_clean.values, y_clean.values, discrete_features=False, random_state=42)\n",
    "\n",
    "    desc[\"ANOVA_F\"] = pd.Series(F_vals, index=eng_cols)\n",
    "    desc[\"ANOVA_p\"] = pd.Series(p_vals, index=eng_cols)\n",
    "    desc[\"MI\"]      = pd.Series(mi_vals, index=eng_cols)\n",
    "\n",
    "    # Order columns nicely\n",
    "    cols = [\n",
    "        \"mean\",\"std\",\"min\",\"q1\",\"median\",\"q3\",\"max\",\"IQR\",\"skew\",\"CV\",\"missing_%\",\"ANOVA_F\",\"ANOVA_p\",\"MI\",\"count\"\n",
    "    ]\n",
    "    return desc[cols].sort_values(\"MI\", ascending=False)\n",
    "\n",
    "def per_class_means(df_eng: pd.DataFrame, y: pd.Series, eng_cols: list):\n",
    "    \"\"\"Return per-class means for engineered features (rows=class, cols=features).\"\"\"\n",
    "    tmp = df_eng[eng_cols].copy()\n",
    "    tmp[\"__y__\"] = y\n",
    "    return tmp.groupby(\"__y__\")[eng_cols].mean().sort_index()\n",
    "\n",
    "# --- Helper: pretty formatting for display in the notebook ---\n",
    "def format_table(df_summary: pd.DataFrame, float_fmt=\"{:.3f}\"):\n",
    "    fmt = df_summary.copy()\n",
    "    for c in fmt.columns:\n",
    "        if pd.api.types.is_float_dtype(fmt[c]):\n",
    "            fmt[c] = fmt[c].map(lambda v: float_fmt.format(v) if pd.notna(v) else \"\")\n",
    "    return fmt\n",
    "\n",
    "summary = summarize_engineered_features(df_eng, y, eng_cols)\n",
    "display(format_table(summary))          # main table (sortable in Jupyter if you use DataFrame explorer)\n",
    "\n",
    "class_means = per_class_means(df_eng, y, eng_cols)\n",
    "display(format_table(class_means))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "04e15cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth=3: train=0.672, test=0.669\n",
      "Depth=7: train=0.722, test=0.720\n",
      "Depth=12: train=0.815, test=0.806\n",
      "Depth=17: train=0.905, test=0.877\n",
      "Depth=24: train=0.981, test=0.929\n",
      "Depth=32: train=1.000, test=0.939\n",
      "Depth=40: train=1.000, test=0.939\n",
      "Depth=None: train=1.000, test=0.939\n",
      "\n",
      "Best depth: 40\n",
      "Best test accuracy: 0.9394828229486554\n",
      "[[59365  3660     2     0    59    10   268]\n",
      " [ 3444 81028   219     1   349   148    43]\n",
      " [    6   218  9935    89    32   433     0]\n",
      " [    0     0    98   718     0    33     0]\n",
      " [   45   369    36     0  2290    12     2]\n",
      " [   10   158   417    41    12  4529     0]\n",
      " [  289    39     0     0     1     0  5807]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.940     0.937     0.938     63364\n",
      "           2      0.948     0.951     0.949     85232\n",
      "           3      0.928     0.927     0.928     10713\n",
      "           4      0.846     0.846     0.846       849\n",
      "           5      0.835     0.832     0.833      2754\n",
      "           6      0.877     0.877     0.877      5167\n",
      "           7      0.949     0.946     0.948      6136\n",
      "\n",
      "    accuracy                          0.939    174215\n",
      "   macro avg      0.903     0.902     0.903    174215\n",
      "weighted avg      0.939     0.939     0.939    174215\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.9026999845299911\n"
     ]
    }
   ],
   "source": [
    "depths = [3, 7, 12, 17, 24, 32, 40, None]\n",
    "best_depth = None\n",
    "best_test_acc = -np.inf\n",
    "best_tree = None\n",
    "\n",
    "for d in depths:  \n",
    "    tree = DecisionTreeClassifier(criterion = 'entropy', max_depth= d, random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    # train_acc_s = tree.score(X_smote, y_smote)\n",
    "    train_acc = tree.score(X_train, y_train)\n",
    "    test_acc = tree.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Depth={d}: train={train_acc:.3f}, test={test_acc:.3f}\")\n",
    "    \n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_depth = d\n",
    "        best_tree = tree\n",
    "\n",
    "print(\"\\nBest depth:\", best_depth)\n",
    "print(\"Best test accuracy:\", best_test_acc)\n",
    "\n",
    "y_pred = best_tree.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c643f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth=3: train=0.319, test=0.316, train_s=0.596\n",
      "Depth=7: train=0.580, test=0.578, train_s=0.732\n",
      "Depth=12: train=0.747, test=0.737, train_s=0.849\n",
      "Depth=17: train=0.880, test=0.853, train_s=0.930\n",
      "Depth=24: train=0.972, test=0.918, train_s=0.984\n",
      "Depth=32: train=0.990, test=0.929, train_s=0.998\n",
      "Depth=40: train=0.992, test=0.929, train_s=1.000\n",
      "Depth=None: train=0.992, test=0.930, train_s=1.000\n",
      "\n",
      "Best depth: None\n",
      "Best test accuracy: 0.9297649456131791\n",
      "[[58997  3758     8     0   117    29   455]\n",
      " [ 4045 79732   407     2   608   359    79]\n",
      " [    7   189  9913   124    35   445     0]\n",
      " [    0     2    92   725     0    30     0]\n",
      " [   56   326    30     0  2324    17     1]\n",
      " [   12   146   476    56    16  4461     0]\n",
      " [  274    34     0     0     1     0  5827]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.931     0.931     0.931     63364\n",
      "           2      0.947     0.935     0.941     85232\n",
      "           3      0.907     0.925     0.916     10713\n",
      "           4      0.799     0.854     0.826       849\n",
      "           5      0.749     0.844     0.794      2754\n",
      "           6      0.835     0.863     0.849      5167\n",
      "           7      0.916     0.950     0.932      6136\n",
      "\n",
      "    accuracy                          0.930    174215\n",
      "   macro avg      0.869     0.900     0.884    174215\n",
      "weighted avg      0.930     0.930     0.930    174215\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.8876424096501319\n"
     ]
    }
   ],
   "source": [
    "depths = [3, 7, 12, 17, 24, 32, 40, None]\n",
    "best_depth = None\n",
    "best_test_acc = -np.inf\n",
    "best_tree = None\n",
    "\n",
    "for d in depths:  \n",
    "    tree = DecisionTreeClassifier(criterion = 'gini', max_depth= d, random_state=42)\n",
    "    tree.fit(X_smote, y_smote)\n",
    "    train_acc_s = tree.score(X_smote, y_smote)\n",
    "    train_acc = tree.score(X_train, y_train)\n",
    "    test_acc = tree.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Depth={d}: train={train_acc:.3f}, test={test_acc:.3f}, train_s={train_acc_s:.3f}\")\n",
    "    \n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_depth = d\n",
    "        s_best_tree = tree\n",
    "\n",
    "print(\"\\nBest depth:\", best_depth)\n",
    "print(\"Best test accuracy:\", best_test_acc)\n",
    "\n",
    "y_pred = s_best_tree.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "54cbcb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth=3: train=0.250, test=0.249, train_s=0.373\n",
      "Depth=7: train=0.138, test=0.136, train_s=0.388\n",
      "Depth=12: train=0.151, test=0.142, train_s=0.424\n",
      "Depth=17: train=0.211, test=0.172, train_s=0.508\n",
      "Depth=24: train=0.401, test=0.249, train_s=0.696\n",
      "Depth=32: train=0.576, test=0.294, train_s=0.869\n",
      "Depth=40: train=0.633, test=0.302, train_s=0.926\n",
      "Depth=None: train=0.647, test=0.301, train_s=0.940\n",
      "\n",
      "Best depth: 40\n",
      "Best test accuracy: 0.30186838102344804\n",
      "[[21255 13834  5170  1994  6781  3595 10735]\n",
      " [19295 24232  8630  3213 10845  6676 12341]\n",
      " [ 1187  1568  2815  1177  1289  1993   684]\n",
      " [   40    50   194   372    56   109    28]\n",
      " [  449   751   363   125   529   267   270]\n",
      " [  425   711  1328   505   561  1420   217]\n",
      " [ 1609  1095   372   145   684   264  1967]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.480     0.335     0.395     63364\n",
      "           2      0.574     0.284     0.380     85232\n",
      "           3      0.149     0.263     0.190     10713\n",
      "           4      0.049     0.438     0.089       849\n",
      "           5      0.026     0.192     0.045      2754\n",
      "           6      0.099     0.275     0.146      5167\n",
      "           7      0.075     0.321     0.122      6136\n",
      "\n",
      "    accuracy                          0.302    174215\n",
      "   macro avg      0.207     0.301     0.195    174215\n",
      "weighted avg      0.471     0.302     0.351    174215\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.10412084747665594\n"
     ]
    }
   ],
   "source": [
    "depths = [3, 7, 12, 17, 24, 32, 40, None]\n",
    "best_depth = None\n",
    "best_test_acc = -np.inf\n",
    "pca_best_tree = None\n",
    "\n",
    "for d in depths:  \n",
    "    tree = DecisionTreeClassifier(criterion = 'gini', max_depth= d, random_state=42)\n",
    "    tree.fit(pca_X_smote, pca_y_smote)\n",
    "    train_acc_s = tree.score(pca_X_smote, pca_y_smote)\n",
    "    train_acc = tree.score(X_train_pca, y_train_pca)\n",
    "    test_acc = tree.score(X_test_pca, y_test_pca)\n",
    "\n",
    "    print(f\"Depth={d}: train={train_acc:.3f}, test={test_acc:.3f}, train_s={train_acc_s:.3f}\")\n",
    "    \n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_depth = d\n",
    "        pca_best_tree = tree\n",
    "\n",
    "print(\"\\nBest depth:\", best_depth)\n",
    "print(\"Best test accuracy:\", best_test_acc)\n",
    "y_pred = pca_best_tree.predict(X_test_pca)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "mcc = matthews_corrcoef(y_test_pca, y_pred)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f06cffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth=3: train=0.318, test=0.315, train_s=0.595\n",
      "Depth=7: train=0.585, test=0.583, train_s=0.718\n",
      "Depth=12: train=0.723, test=0.712, train_s=0.825\n",
      "Depth=17: train=0.846, test=0.805, train_s=0.903\n",
      "Depth=24: train=0.954, test=0.859, train_s=0.974\n",
      "Depth=32: train=0.981, test=0.865, train_s=0.997\n",
      "Depth=40: train=0.983, test=0.865, train_s=1.000\n",
      "Depth=None: train=0.983, test=0.866, train_s=1.000\n",
      "\n",
      "Best depth: None\n",
      "Best test accuracy: 0.8657693080389174\n",
      "[[54679  7733    27     0   169    44   712]\n",
      " [ 7946 74954   582     3  1031   607   109]\n",
      " [   14   293  9035   220    62  1089     0]\n",
      " [    0     3   172   589     0    85     0]\n",
      " [   80   493    51     0  2102    27     1]\n",
      " [   16   252   934    78    19  3868     0]\n",
      " [  455    78     0     0     0     0  5603]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.865     0.863     0.864     63364\n",
      "           2      0.894     0.879     0.887     85232\n",
      "           3      0.836     0.843     0.840     10713\n",
      "           4      0.662     0.694     0.677       849\n",
      "           5      0.621     0.763     0.685      2754\n",
      "           6      0.676     0.749     0.711      5167\n",
      "           7      0.872     0.913     0.892      6136\n",
      "\n",
      "    accuracy                          0.866    174215\n",
      "   macro avg      0.775     0.815     0.794    174215\n",
      "weighted avg      0.868     0.866     0.866    174215\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.7857572921847582\n"
     ]
    }
   ],
   "source": [
    "depths = [3, 7, 12, 17, 24, 32, 40, None]\n",
    "best_depth = None\n",
    "best_test_acc = -np.inf\n",
    "e_best_tree = None\n",
    "\n",
    "for d in depths:  \n",
    "    tree = DecisionTreeClassifier(criterion = 'gini', max_depth= d, random_state=42)\n",
    "    tree.fit(eX_smote, ey_smote)\n",
    "    train_acc_s = tree.score(eX_smote, ey_smote)\n",
    "    train_acc = tree.score(eX_train, ey_train)\n",
    "    test_acc = tree.score(eX_test, ey_test)\n",
    "\n",
    "    print(f\"Depth={d}: train={train_acc:.3f}, test={test_acc:.3f}, train_s={train_acc_s:.3f}\")\n",
    "    \n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_depth = d\n",
    "        e_best_tree = tree\n",
    "\n",
    "print(\"\\nBest depth:\", best_depth)\n",
    "print(\"Best test accuracy:\", best_test_acc)\n",
    "y_pred = e_best_tree.predict(eX_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "mcc = matthews_corrcoef(ey_test, y_pred)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d9e48110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate k values: [14, 10, 7, 4]\n",
      "k=14: train=0.771, test=0.735\n",
      "k=10: train=0.792, test=0.743\n",
      "k=7: train=0.821, test=0.756\n",
      "k=4: train=0.862, test=0.769\n",
      "\n",
      "Best k: 4\n",
      "Best test accuracy: 0.7691702781046408\n",
      "[[53575  8988    28     0   104    15   654]\n",
      " [16080 67214  1045     2   462   348    81]\n",
      " [   47  2071  7422   158    24   991     0]\n",
      " [    0     9   587   147     0   106     0]\n",
      " [  193  1781    52     0   720     8     0]\n",
      " [   34  1015  2514    44    16  1544     0]\n",
      " [ 2599   158     0     0     0     0  3379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.739     0.846     0.788     63364\n",
      "           2      0.827     0.789     0.808     85232\n",
      "           3      0.637     0.693     0.664     10713\n",
      "           4      0.419     0.173     0.245       849\n",
      "           5      0.543     0.261     0.353      2754\n",
      "           6      0.513     0.299     0.378      5167\n",
      "           7      0.821     0.551     0.659      6136\n",
      "\n",
      "    accuracy                          0.769    174215\n",
      "   macro avg      0.643     0.516     0.556    174215\n",
      "weighted avg      0.767     0.769     0.764    174215\n",
      "\n",
      "Matthews Correlation Coefficient (MCC): 0.6265333046611687\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# number of descriptive features\n",
    "N = kX_train.shape[1]\n",
    "\n",
    "# define k values\n",
    "k_values = [\n",
    "    int(2 * np.sqrt(N)),\n",
    "    int(3 + np.sqrt(N)),\n",
    "    int(np.sqrt(N)),\n",
    "    max(1, int(np.sqrt(N) - 3))  # avoid k < 1\n",
    "]\n",
    "\n",
    "print(\"Candidate k values:\", k_values)\n",
    "\n",
    "best_k = None\n",
    "best_test_acc = -np.inf\n",
    "best_knn = None\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=\"minkowski\", weights=\"uniform\")\n",
    "    knn.fit(kX_train, y_train)\n",
    "\n",
    "    train_acc = knn.score(kX_train, y_train)\n",
    "    test_acc = knn.score(kX_test, y_test)\n",
    "\n",
    "    print(f\"k={k}: train={train_acc:.3f}, test={test_acc:.3f}\")\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_k = k\n",
    "        best_knn = knn\n",
    "\n",
    "print(\"\\nBest k:\", best_k)\n",
    "print(\"Best test accuracy:\", best_test_acc)\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_knn.predict(kX_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a56b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate k values: [14, 10, 7, 4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# number of descriptive features\n",
    "N = keX_smote.shape[1]\n",
    "\n",
    "# define k values\n",
    "k_values = [\n",
    "    int(2 * np.sqrt(N)),\n",
    "    int(3 + np.sqrt(N)),\n",
    "    int(np.sqrt(N)),\n",
    "    max(1, int(np.sqrt(N) - 3))  # avoid k < 1\n",
    "]\n",
    "\n",
    "print(\"Candidate k values:\", k_values)\n",
    "\n",
    "best_k = None\n",
    "best_test_acc = -np.inf\n",
    "best_knn = None\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=\"minkowski\", weights=\"uniform\")\n",
    "    knn.fit(keX_smote, key_smote)\n",
    "\n",
    "    train_acc = knn.score(keX_smote, key_smote)\n",
    "    test_acc = knn.score(kX_test, y_test)\n",
    "\n",
    "    print(f\"k={k}: train={train_acc:.3f}, test={test_acc:.3f}\")\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_k = k\n",
    "        best_knn = knn\n",
    "\n",
    "print(\"\\nBest k:\", best_k)\n",
    "print(\"Best test accuracy:\", best_test_acc)\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_knn.predict(kX_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055421de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of descriptive features\n",
    "N = kX_smote.shape[1]\n",
    "\n",
    "# define k values\n",
    "k_values = [\n",
    "    int(2 * np.sqrt(N)),\n",
    "    int(3 + np.sqrt(N)),\n",
    "    int(np.sqrt(N)),\n",
    "    max(1, int(np.sqrt(N) - 3))  # avoid k < 1\n",
    "]\n",
    "\n",
    "print(\"Candidate k values:\", k_values)\n",
    "\n",
    "best_k = None\n",
    "best_test_acc = -np.inf\n",
    "best_knn = None\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=\"minkowski\", weights=\"uniform\")\n",
    "    knn.fit(kX_smote, ky_smote)\n",
    "\n",
    "    train_acc = knn.score(kX_smote, ky_smote)\n",
    "    test_acc = knn.score(kX_test, y_test)\n",
    "\n",
    "    print(f\"k={k}: train={train_acc:.3f}, test={test_acc:.3f}\")\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_k = k\n",
    "        best_knn = knn\n",
    "\n",
    "print(\"\\nBest k:\", best_k)\n",
    "print(\"Best test accuracy:\", best_test_acc)\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_knn.predict(kX_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ce747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of descriptive features\n",
    "N = pca_kXsmote.shape[1]\n",
    "\n",
    "# define k values\n",
    "k_values = [\n",
    "    int(2 * np.sqrt(N)),\n",
    "    int(3 + np.sqrt(N)),\n",
    "    int(np.sqrt(N)),\n",
    "    max(1, int(np.sqrt(N) - 3))  # avoid k < 1\n",
    "]\n",
    "\n",
    "print(\"Candidate k values:\", k_values)\n",
    "\n",
    "best_k = None\n",
    "best_test_acc = -np.inf\n",
    "best_knn = None\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=\"minkowski\", weights=\"uniform\")\n",
    "    knn.fit(pca_kXsmote, pca_kysmote)\n",
    "\n",
    "    train_acc = knn.score(pca_kXsmote, pca_kysmote)\n",
    "    test_acc = knn.score(kX_test, y_test)\n",
    "\n",
    "    print(f\"k={k}: train={train_acc:.3f}, test={test_acc:.3f}\")\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_k = k\n",
    "        best_knn = knn\n",
    "\n",
    "print(\"\\nBest k:\", best_k)\n",
    "print(\"Best test accuracy:\", best_test_acc)\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_knn.predict(kX_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
