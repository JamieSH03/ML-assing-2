{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aab0d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, cohen_kappa_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"../forestCover.csv\", na_values=\"?\")\n",
    "raw_df = raw_df.rename(columns={\"Observation_ID\":\"Water_Level\" , \"Water_Level\":\"Observation_ID\"})\n",
    "# display(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_col = raw_df.columns[raw_df.isna().any()]\n",
    "# print(na_col)\n",
    "raw_df[\"Slope\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a210d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Corr of Inclination and Cover: {raw_df['Inclination'].corr(raw_df['Cover_Type'])}\")\n",
    "print(f\"Corr of aspect and facet: {raw_df['Facet'].corr(raw_df['Aspect'])}\")\n",
    "print(f\"Cardinality of water level: {raw_df['Water_Level'].nunique()}\")\n",
    "print(f\"Cardinality of obs id: {raw_df['Observation_ID'].nunique()}\")\n",
    "df = raw_df.drop(columns={'Facet','Water_Level','Observation_ID', 'Inclination' })\n",
    "\n",
    "na_rows = df.index[df.isna().any(axis=1)]\n",
    "na_proportions = (df[\"Cover_Type\"][na_rows].value_counts() /  df[\"Cover_Type\"].value_counts() * 100).round(3)\n",
    "print(na_proportions)\n",
    "df = df.dropna()\n",
    "\n",
    "df[\"Soil_Type1\"] = (df[\"Soil_Type1\"] == 'positive').astype(int)\n",
    "df[\"Soil_Type1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb54ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\"\n",
    "]\n",
    "\n",
    "# Plot distributions\n",
    "fig, axes = plt.subplots(len(continuous_features), 1, figsize=(5, 15))\n",
    "\n",
    "for i, col in enumerate(continuous_features):\n",
    "    sns.histplot(df[col], bins=50, kde=True, ax=axes[i], color=\"steelblue\")\n",
    "    axes[i].set_title(f\"Distribution of {col}\")\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5da20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = df.copy()\n",
    "df_eng[\"Relative_hoz_dist_mean\"] = df[[\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Horizontal_Distance_To_Roadways\"\n",
    "]].mean(axis=1)\n",
    "\n",
    "df_eng[\"total_hillshade\"] = df[[\"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\"]].sum(axis=1)\n",
    "df_eng[\"Relative_height_from_water\"] = df[\"Elevation\"] - df[\"Vertical_Distance_To_Hydrology\"]\n",
    "df_eng = df_eng.drop(columns={\"Elevation\",  \"Vertical_Distance_To_Hydrology\",\"Horizontal_Distance_To_Hydrology\", \"Horizontal_Distance_To_Fire_Points\",\"Horizontal_Distance_To_Roadways\",\"Hillshade_9am\",\"Hillshade_Noon\", \"Hillshade_3pm\"  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns={\"Cover_Type\"})\n",
    "X_eng = df_eng.drop(columns={\"Cover_Type\"})\n",
    "y = df[\"Cover_Type\"]\n",
    "y_eng = df_eng[\"Cover_Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "eX_train, eX_test, ey_train, ey_test = train_test_split(X_eng, y_eng, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_features = [\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "]\n",
    "\n",
    "outlier_features_eng = [\n",
    "    \"Relative_hoz_dist_mean\",\n",
    "    \n",
    "]\n",
    "\n",
    "knn_df = df.copy()\n",
    "knn_eng = df.copy()\n",
    "\n",
    "\n",
    "def clamp_series(s, lower_q=0.01, upper_q=0.99):\n",
    "    lower, upper = s.quantile([lower_q, upper_q])\n",
    "    return s.clip(lower, upper)\n",
    "\n",
    "# apply clamping\n",
    "for col in outlier_features:\n",
    "    knn_df[col] = clamp_series(knn_df[col], 0.01, 0.99)\n",
    "    \n",
    "\n",
    "knn_eng[\"Relative_hoz_dist_mean\"] = clamp_series(knn_eng[\"Relative_hoz_dist_mean\"], 0.01, 0.99)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "continuous_features = [\n",
    "\n",
    "    \"Elevation\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "]\n",
    "\n",
    "continuous_features_eng = [\n",
    "\n",
    "    'Slope', \n",
    "    'Relative_hoz_dist_mean', \n",
    "    'total_hillshade',\n",
    "    'Relative_height_from_water'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scale_knn(knn_df, continuous_features = continuous_features):\n",
    "    scaler = MinMaxScaler()\n",
    "    knn_df[continuous_features] = scaler.fit_transform(knn_df[continuous_features])\n",
    "    knn_df[\"Aspect_rad\"] = np.deg2rad(knn_df[\"Aspect\"])\n",
    "    knn_df[\"Aspect_sin\"] = np.sin(knn_df[\"Aspect_rad\"])\n",
    "    knn_df[\"Aspect_cos\"] = np.cos(knn_df[\"Aspect_rad\"])\n",
    "    knn_df.drop(columns=[\"Aspect\", \"Aspect_rad\"] , inplace=True)\n",
    "\n",
    "\n",
    "scale_knn(knn_df)\n",
    "scale_knn(knn_eng)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95985ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns={\"Cover_Type\"})\n",
    "X_eng = df_eng.drop(columns={\"Cover_Type\"})\n",
    "y = df[\"Cover_Type\"]\n",
    "y_eng = df_eng[\"Cover_Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "eX_train, eX_test, ey_train, ey_test = train_test_split(X_eng, y_eng, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "kX = df.drop(columns={\"Cover_Type\"})\n",
    "kX_eng = df_eng.drop(columns={\"Cover_Type\"})\n",
    "ky = df[\"Cover_Type\"]\n",
    "ky_eng = df_eng[\"Cover_Type\"]\n",
    "\n",
    "kX_train, kX_test, ky_train, ky_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "keX_train, keX_test, key_train, key_test = train_test_split(X_eng, y_eng, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.9)\n",
    "X_pca = pca.fit_transform(X)\n",
    "kX_pca = pca.fit(kX)\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "kX_train_pca, kX_test_pca, ky_train_pca, ky_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc79693",
   "metadata": {},
   "source": [
    "## dealing with class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c22edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tomek = TomekLinks(sampling_strategy='auto')\n",
    "X_tomek, y_tomek = tomek.fit_resample(X_train, y_train)\n",
    "eX_tomek, ey_tomek = tomek.fit_resample(eX_train, ey_train)\n",
    "\n",
    "kX_tomek, ky_tomek = tomek.fit_resample(kX_train, ky_train)\n",
    "keX_tomek, key_tomek = tomek.fit_resample(keX_train, key_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf338cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTETomek(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "eX_smote, ey_smote = smote.fit_resample(eX_train, ey_train)\n",
    "pca_X_smote, pca_y_smote = smote.fit_resample(X_train_pca, y_train_pca)\n",
    "\n",
    "\n",
    "kX_smote, ky_smote = smote.fit_resample(kX_train, ky_train)\n",
    "keX_smote, key_smote = smote.fit_resample(keX_train, key_train)\n",
    "pca_kXsmote, pca_kysmote = smote.fit_resample(kX_train_pca, ky_train_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fc1dd",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2fe64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, cv=5):\n",
    "    # Accuracy with mean ± std\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    print(f\"Accuracy: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "    \n",
    "    # Cross-validated predictions for confusion matrix etc.\n",
    "    y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix ({type(model).__name__})\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification report (precision, recall, f1 per class)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, y_pred, digits=3))\n",
    "    \n",
    "    # Cohen’s kappa (agreement beyond chance)\n",
    "    kappa = cohen_kappa_score(y, y_pred)\n",
    "    print(f\"Cohen’s Kappa: {kappa:.3f}\")\n",
    "\n",
    "def plot_cv_boxplot(model, X, y, cv=5):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    sns.boxplot(data=scores, orient=\"h\", color=\"skyblue\")\n",
    "    plt.title(f\"Accuracy per fold ({type(model).__name__})\")\n",
    "    plt.xlabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, cv=cv, train_sizes=train_sizes, scoring=\"accuracy\"\n",
    "    )\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(train_sizes, train_mean, \"o-\", label=\"Training\")\n",
    "    plt.plot(train_sizes, val_mean, \"o-\", label=\"Validation\")\n",
    "    plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, alpha=0.2)\n",
    "    plt.fill_between(train_sizes, val_mean-val_std, val_mean+val_std, alpha=0.2)\n",
    "    plt.title(f\"Learning Curve ({type(model).__name__})\")\n",
    "    plt.xlabel(\"Training set size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a716a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84f911a2",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_knn(X_train , y_train, X_test = kX_test, y_test = ky_test, weights = 'distance' , k = 5, metric = \"euclidean\"):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=metric, weights=weights)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_acc = knn.score(X_train, y_train)\n",
    "    test_acc = knn.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c66da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_knn(kX_tomek, ky_tomek)\n",
    "test_knn(keX_tomek, key_tomek, X_test=keX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9400d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_knn(kX_smote, ky_tomek)\n",
    "test_knn(keX_smote, key_smote, X_test=keX_test)\n",
    "test_knn(pca_kXsmote,pca_kysmote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c1e39",
   "metadata": {},
   "source": [
    "### tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tree(X_train, y_train, X_test = X_test, y_test = y_test, metric = 'entropy', max_depth = None):\n",
    "    tree = DecisionTreeClassifier(criterion = metric, max_depth= max_depth, random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    train_acc = tree.score(X_train, y_train)\n",
    "    test_acc = tree.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Smote train acc: {train_acc}\")\n",
    "    print(f\"Smote test acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree(X_tomek, y_tomek)\n",
    "test_tree(eX_tomek, ey_tomek, X_test=eX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c5af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree(X_smote, y_tomek)\n",
    "test_tree(eX_smote, ey_smote, X_test=eX_test)\n",
    "test_tree(pca_X_smote,pca_y_smote)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
